{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Transform\n",
    "\n",
    "**NOTE**: I will not copy all the precise definitions (please Google if needed) here. The explainations below are my own words for easy understanding.\n",
    "\n",
    "## 6.1 Kernal and Range\n",
    "\n",
    "**Transform** means a function that convert input $x$ to output $y$. Please note $x$ and $y$ are not necessarily single values or of same dimension, or even numbers.\n",
    "\n",
    "**Domain** is the range of all possible input $x$.\n",
    "\n",
    "**Codomain** is the range of all possible $y$. Basically it means where $y$ is from (e.g. all integers), ***not necessarily*** each $y$ in codomain must be able to get from the function of interest.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the `int()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int(3.24) = 3\n"
     ]
    }
   ],
   "source": [
    "x = 3.24\n",
    "y = int(x)\n",
    "print(f'int({x}) = {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its domain is real number, but the codomain is integer.\n",
    "\n",
    "---\n",
    "\n",
    "A result of a function is called a **image**, and a set of images is called **range**. Range is a ***subset*** of codomain.\n",
    "\n",
    "Simply put, range is all $y$ that can be get from the function of interest.\n",
    "\n",
    "***3 types of relationships*** between domain, codomain and range:  \n",
    "1. **Injective**: each $x$ points to one specific (no repetition) $y$.\n",
    "    - Each $x$ must have one $y$.\n",
    "    - Different $x$ have different $y$.\n",
    "    - NOT necessarily each $y$ (in codomain) can find its $x$.\n",
    "2. **Surjective**: range = codomain.\n",
    "    - Each $y$ must have its $x$ (maybe more than one $x$)\n",
    "3. **Bijective**: One-to-one correspondece between $x$ and $y$\n",
    "    - Each $x$ has its one specific $y$\n",
    "    - Each $y$ has its one specific $x$\n",
    "    - **Bijective** = **Injective** AND **Surjective**\n",
    "\n",
    "---\n",
    "\n",
    "A transformation of linear combination is called **linear transformation**.\n",
    "\n",
    "In below context, transformation means linear transformation.\n",
    "\n",
    "$T:V\\to W$ ($T$ means transformation, $V$ and $W$ are vector spaces), below criterias must hold:  \n",
    "1. $T(v_1+v_2)=T(v_1)+T(v_2)$ for any vectors $v_1$ and $v_2$ in $V$\n",
    "2. $T(\\alpha v)=\\alpha T(v)$ for any scalar $\\alpha$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a linear transformation, when the range is all 0, the domain is called the **kernel**.\n",
    "\n",
    "How to understand **kernel**?  \n",
    "- Kernel means all the vectors in $V$ that will be mapped to 0 in $W$ by $T$, which is effectively the ***nullspace*** of matrix $T$.\n",
    "- Kernel is related to dimension shrinkage after transformation.\n",
    "    - Consider $T(x,y,z)\\to (0,y,z)$, basically this transformation is to squeeze the whole $x$ axis line into one zero point.\n",
    "    - Thus all the vectors lie on $x$ axis form the kernel space\n",
    "    - $ker(T)=Span\\{<1,0,0>\\}$\n",
    "    - Dimension: $V=3$, $W=2$, $ker(T)=1$\n",
    "- ***dim domain + dim kernel = dim codomain***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Linear transformation\n",
    "\n",
    "Not all linear combinations are linear transformations. Key point is the transformation should **NOT** move 0 vector.\n",
    "\n",
    "Consider below transformation, is it linear?  \n",
    "$$T(<x_1,x_2,x_3>)=<2x_1+x_3, -4x_2>$$  \n",
    "We can rewrite the equation as below:  \n",
    "$$\\begin{bmatrix}\n",
    "2 & 0 & 1 \\\\\n",
    "0 & -4 & 0\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Matrix([\n",
       " [1, 0, 1/2],\n",
       " [0, 1,   0]]),\n",
       " (0, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = sympy.Matrix([[2,0,1],\n",
    "                  [0,-4,0]])\n",
    "A.rref()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rref of the standard matrix A is a linearly dependent containing one free variable, and a linear combination is established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T(v1) + T(v2) = T(v1 + v2) ?\n",
      "[ True  True]\n",
      "\n",
      "c*T(v1) = T(c*v1) ?\n",
      "[ True  True]\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([3,6,9])\n",
    "v2 = np.array([2,5,8])\n",
    "c = 6\n",
    "\n",
    "def trans1(x):\n",
    "    y1 = 2*x[0] + x[2]\n",
    "    y2 = -4 * x[1]\n",
    "    return(np.array([y1, y2]))\n",
    "\n",
    "print('T(v1) + T(v2) = T(v1 + v2) ?')\n",
    "print(np.equal(trans1(v1+v2), trans1(v1)+trans1(v2)))\n",
    "\n",
    "print('\\nc*T(v1) = T(c*v1) ?')\n",
    "print(np.equal(6*trans1(v1), trans1(6*v1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation satisfies the requirement of linear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans1([0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the zero vector is still zero vector after transformation, though space dimension is changed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the equation below is a linear transformation:  \n",
    "$$T(<x_1,x_2,x_3>)=<4x_1+2x_2,0,x_1+3x_3-2>$$  \n",
    "We can rewrite it in the form below:  \n",
    "$$\\begin{bmatrix}\n",
    "4 & 2 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "1 & 0 & 3 & -2\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "1\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Matrix([\n",
       " [1, 0,  3, -2],\n",
       " [0, 1, -6,  4],\n",
       " [0, 0,  0,  0]]),\n",
       " (0, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = sympy.Matrix([[4,2,0,0],\n",
    "                  [0,0,0,0],\n",
    "                  [1,0,3,-2]])\n",
    "A.rref()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two leading variables depend not only on another free variable, but on constant as well:  \n",
    "$$\\begin{align*}\n",
    "x_1 &= -3x_3+2\\\\\n",
    "x_2 &= 6x_3-4\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T(v1) + T(v2) = T(v1 + v2) ?\n",
      "[ True  True False]\n",
      "\n",
      "c*T(v1) = T(c*v1) ?\n",
      "[ True  True False]\n"
     ]
    }
   ],
   "source": [
    "def trans2(x):\n",
    "    y1 = 4*x[0]+2*x[1]\n",
    "    y2 = 0\n",
    "    y3 = x[0]+3*x[2]-2\n",
    "    return(np.array([y1,y2,y3]))\n",
    "\n",
    "print('T(v1) + T(v2) = T(v1 + v2) ?')\n",
    "print(np.equal(trans2(v1+v2), trans2(v1)+trans2(v2)))\n",
    "\n",
    "print('\\nc*T(v1) = T(c*v1) ?')\n",
    "print(np.equal(6*trans2(v1), trans2(6*v1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This linear combination is **NOT** a linear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, -2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans2([0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the zero vector is ***shifted*** by this transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Special Linear Transform\n",
    "#### 6.2.1.1 Linear transformation in the same dimension\n",
    "\n",
    "If a square matrix is reversible, then this linear transformation is bijective, one-to-one mapping of vectors in the same space:  \n",
    "$$Ax=y\\to A^{-1} y=x$$\n",
    "\n",
    "#### 6.2.1.2 Rotate a certain angle\n",
    "\n",
    "$$R_\\theta = \\begin{bmatrix}\n",
    "\\cos(\\theta) & -\\sin(\\theta) \\\\\n",
    "\\sin(\\theta) & \\cos(\\theta)\n",
    "\\end{bmatrix}$$\n",
    "In 2d linear space, above matrix transforms vectors counterclockwise by angle $\\theta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70710678]\n",
      " [3.53553391]]\n"
     ]
    }
   ],
   "source": [
    "# rotate vector b counterclockwise by 45 deg\n",
    "theta = np.deg2rad(45)\n",
    "R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "              [np.sin(theta), np.cos(theta)]])\n",
    "b = np.array([[3], [2]])\n",
    "print(np.dot(R, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Orthogonal set and projection\n",
    "### 6.3.1 Orthogonal set\n",
    "\n",
    "In a vector set, if the vectors are perpendicular to each other, then it is an **orthogonal set**:  \n",
    "$$\\text{set} \\{u_1,u_2,\\dots ,u_n\\}\\in R^n\\\\\n",
    "u_i\\cdot u_j=0, i\\neq j$$\n",
    "\n",
    "It is easy to prove that an dimension $n$ orthogonal set is linearly independent and forms base vectors of $R^n$.\n",
    "\n",
    "It is easy to understand. In a 3d space, (x, y, z) axis naturally form one orthogonal set. Any other orthogonal set can be linearly transformed from these axis by rotating the space.\n",
    "\n",
    "### 6.3.2 Orthogonal Projection\n",
    "\n",
    "Consider 2 vectors $u$ and $z$, we can split $z$ into another 2 vectors:  \n",
    "$$z=\\hat u + v$$  \n",
    "- $\\hat u$ is aligned with $u$\n",
    "- $v$ is perpendicular to $u$\n",
    "\n",
    "This process is called **orthogonal projection** of $z$ on $u$.\n",
    "\n",
    "Calculation can be done with below equations:  \n",
    "$$\\begin{align*}\n",
    "\\hat u&=\\frac{z\\cdot u}{\\left\\| u \\right\\|^2}\\cdot u = \\frac{z\\cdot u}{u\\cdot u}\\cdot u \\\\\n",
    "v &= z - \\hat u = z-\\frac{z\\cdot u}{u\\cdot u}\\cdot u\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    z = [7 6]\n",
      "    u = [4 2]\n",
      "hat_u = [8. 4.]\n",
      "    v = [-1.  2.]\n"
     ]
    }
   ],
   "source": [
    "z = np.array([7,6])\n",
    "u = np.array([4,2])\n",
    "zu = np.dot(z.T, u)\n",
    "uu = np.dot(u.T, u)\n",
    "hat_u = zu/uu*u\n",
    "v = z - hat_u\n",
    "\n",
    "print('    z =', z)\n",
    "print('    u =', u)\n",
    "print('hat_u =', hat_u)\n",
    "print('    v =', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Orthonormal\n",
    "\n",
    "An orthogonal set is **orthonormal** if all the vectors are normal (unit, length of 1).\n",
    "\n",
    "Simple example: all the unit vectors on axis x, y, z, etc. form orthonormal set.\n",
    "\n",
    "Orthonormal matrix $U$ has an interesting feature:  \n",
    "$$U^\\text T \\cdot U=I \\Longleftrightarrow U^\\text T = U^{-1}$$\n",
    "\n",
    "It is easy to prove (not shown here). We can use this feature to check if a matrix is orthonormal.\n",
    "\n",
    "Transformation by orthonormal matrix simply rotate the vectors in the space, perserving their length and angle between each other:  \n",
    "- $\\left\\| Ux \\right\\|=\\left\\| x \\right\\|$ (preserve size)\n",
    "- $(Ux)\\cdot (Uy)=x\\cdot y$ (preserve angle between $x$ and $y$)\n",
    "- $x\\cdot y=0 \\to (Ux)\\cdot (Uy)=0$ (preserve orthogonal relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.4 Gram-Schmidt Process\n",
    "\n",
    "**Gram-Schmidt Process** is an algorithm to generate orthogonal or orthonormal basis in a subspace (non zero) of $R^n$.  \n",
    "$$W=Span\\{x_1, x_2, \\dots , x_n\\} \\to \\{v_1, v_2, \\dots , v_n\\}$$  \n",
    "Where $X$ is a basis set of subspace $W$ and we want to calculate orthogonal basis set $V$.  \n",
    "1. $v_1 = x_1$\n",
    "2. $v_2 = x_2 - \\frac{x_2\\cdot v_1}{v_1\\cdot v_1}v_1$\n",
    "    - Take $x_2$ orthogonal projection on $v_1$, keep only the orthogonal part and assign it as $v_2$\n",
    "3. $v_3 = x_3 - \\frac{x_3\\cdot v_1}{v_1\\cdot v_1}v_1 - \\frac{x_3\\cdot v_2}{v_2\\cdot v_2}v_2$\n",
    "    - Take $x_3$ orthogonal projection on $v_1$ and $v_2$, keep only the orthogonal part and assign it as $v_3$\n",
    "4. Continue this way to find all $v_n$\n",
    "5. If you want orthonormal basis, simply rescale all $v_n$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate orthogonal basis vectors from the basis set $\\{x_1,x_2,x_3\\}$ of $W$, which is a subspace of $R^4$.  \n",
    "$$x_1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \n",
    "x_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \n",
    "x_3 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.75        0.        ]\n",
      " [ 1.          0.25       -0.66666667]\n",
      " [ 1.          0.25        0.33333333]\n",
      " [ 1.          0.25        0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "def orthoCoefS(x, y):\n",
    "    \"\"\"Coefficient of x orthogonal projection on y\"\"\"\n",
    "    return np.dot(x.T, y) / np.dot(y.T, y)\n",
    "\n",
    "x1 = np.array([1,1,1,1]).reshape(-1,1)\n",
    "x2 = np.array([0,1,1,1]).reshape(-1,1)\n",
    "x3 = np.array([0,0,1,1]).reshape(-1,1)\n",
    "\n",
    "v1 = x1\n",
    "v2 = x2 - orthoCoefS(x2, v1)*v1\n",
    "v3 = x3 - orthoCoefS(x3, v1)*v1 - orthoCoefS(x3, v2)*v2\n",
    "\n",
    "print(np.hstack([v1, v2, v3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Similarity transformation\n",
    "\n",
    "For 2 squre matrices $A$ and $B$ of same dimension, if there exists another reversible matrix $P$ satisfying below criteria, then $A$ and $B$ are said to be **similar**, and the transformation below is called a **similarity transformation**.  \n",
    "$$A=PBP^{-1}\\equiv P^{-1}AP=B$$\n",
    "\n",
    "How to understand similarity transformation?  \n",
    "- 3b1b video provides a great explaination, please watch if you haven't yet.\n",
    "- Simply put, $A$ and $B$ are same transformation under different basis set. $P$ is the transformation to translate matrix from $B$ basis to $A$ basis. $P^{-1}$ is the to translate matrix from $A$ basis back to $B$ basis.\n",
    "- Since $A$ and $B$ do same thing under different basis, of course they are similar.\n",
    "\n",
    "If you are still confusing, try to understand with below example:  \n",
    "- Define:\n",
    "    - $A$: a linear algebra student who only reads **English**.\n",
    "    - $B$: another student who only reads **Chinese**.\n",
    "    - $P$: translate **Chinese to English**.\n",
    "    - $p^{-1}$: translate **English back to Chinese**.\n",
    "    - $x$: a linear algebra problem in ***English***\n",
    "- Can you see why $A=PBP^{-1}$ or $A\\cdot x=PBP^{-1}\\cdot x$?\n",
    "    - $A\\cdot x$: student $A$ solves problem $x$\n",
    "    - $PBP^{-1}\\cdot x$: student $B$ solves problem $x$, but because $B$ cannot directly read $x$ in English, this process takes 3 steps:\n",
    "        1. $P^{-1}\\cdot x$: translate $x$ from English to Chinese\n",
    "        2. $BP^{-1}\\cdot x$: student $B$ solves translated $x$ in Chinese\n",
    "        3. $PBP^{-1}\\cdot x$: translate $B$'s solution back to English\n",
    "    - Both $A\\cdot x$ and $PBP^{-1}\\cdot x$ show same final results: getting problem $x$ solved in English. So $A\\cdot x=PBP^{-1}\\cdot x$, or $A=PBP^{-1}$.\n",
    "\n",
    "To test if you have really digested this concept, think about this question:  \n",
    "- If $A$ and $B$ are similar, then they have same rank and eigenvalues.\n",
    "- Is above statement correct? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Diagonalization\n",
    "\n",
    "Transform matrix $A$ into a diagonal matrix $D$ via a similarity transformation is called **diagonalization** of $A$:  \n",
    "$$D=P^{-1}AP$$\n",
    "\n",
    "Why do we want to find $A$'s diagonalization form?  \n",
    "1. You know diagonal matrix is very easy to calculate:\n",
    "    - **Rank**: number of non zero diagonal elements.\n",
    "    - **Trace**: sum of diagonal elements.\n",
    "    - **Eigenvalues**: Non zero diagonal elements\n",
    "    - ... (many others)\n",
    "2. You also know (or you don't?) similar matrices share same:\n",
    "    - **Rank**, **trace**, **eigenvalues**, ...\n",
    "3. $A^k$ is also similar to $D^k$, and exponential power of $D$ is super easy to calculate:  \n",
    "$$D^k=\\begin{bmatrix}\n",
    "{d_1}^k & 0 & \\dots & 0 \\\\\n",
    "0 & {d_2}^k & \\cdots  & 0 \\\\\n",
    "\\vdots  & \\vdots  & \\ddots  & \\vdots  \\\\\n",
    "0 & 0 & \\dots & {d_n}^k\n",
    "\\end{bmatrix}$$\n",
    "- Now you know why it is a good idea to diagonalize $A$.\n",
    "\n",
    "Now the question is how to diagonalize a matrix. In Python you can do it easily using `sympy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Matrix([\n",
       " [0, 1, 1,  0],\n",
       " [1, 1, 1, -1],\n",
       " [1, 1, 1,  0],\n",
       " [1, 1, 0,  1]]),\n",
       " Matrix([\n",
       " [-2, 0, 0, 0],\n",
       " [ 0, 3, 0, 0],\n",
       " [ 0, 0, 5, 0],\n",
       " [ 0, 0, 0, 5]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sympy.Matrix([[3,-2,4,-2],\n",
    "                  [5,3,-3,-2],\n",
    "                  [5,-2,2,-2],\n",
    "                  [5,-2,-3,3]])\n",
    "M.diagonalize() # return P, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in how to do it mathematically, please read: --> [Link](https://yutsumura.com/how-to-diagonalize-a-matrix-step-by-step-explanation/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZZ_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
